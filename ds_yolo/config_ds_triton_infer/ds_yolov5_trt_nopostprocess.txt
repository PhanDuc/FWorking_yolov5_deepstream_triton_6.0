
infer_config {
  # unique ID of the gst-nvinfer instance 
  unique_id: 1
  gpu_ids: [0]
  max_batch_size: 4
  backend {
    inputs [
      {
        name: "data"
        #dims: [ 3, 640, 640 ]
      }
    ]
    triton {
      model_name: "yolov5_flag_trt"
      version: -1
      model_repo {
        root: "/models"
        log_level: 2
        strict_model_config: true
      }
    }
  }

  preprocess {
    network_format: IMAGE_FORMAT_RGB
    tensor_order: TENSOR_ORDER_LINEAR
    frame_scaling_hw: FRAME_SCALING_HW_GPU
    maintain_aspect_ratio: 0
    symmetric_padding: 1
    #frame_scaling_filter: 1
    normalize {
      scale_factor: 0.00392156862745098
      channel_offsets: [0, 0, 0]
    }
  }
  
  # Postprocess at client
  postprocess {
    #labelfile_path: "/opt/nvidia/deepstream/deepstream-6.0/sources/YOLOv5_Deepstream_6.0/deepstream_triton_yolov5/labels.txt"
    other {}
  }

  extra {
    copy_input_to_host_buffers: false
  }

  # custom library for yolov5 tensorrt
  custom_lib {
    path: "/plugins/libmyplugins.so"
  }
}

input_control {
  process_mode: PROCESS_MODE_FULL_FRAME
  interval: 0 # skip_frames arguments
  async_mode: false
}

# Allow triton inference output is metadata.
output_control {
  output_tensor_meta: true
}


